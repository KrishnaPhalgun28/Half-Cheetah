{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmented Random Search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Tkb4J2YZOj"
      },
      "source": [
        "!pip install gym==0.10.5\n",
        "# !pip install pybullet # 3.0.8\n",
        "!pip install pybullet==2.0.8\n",
        "!pip install ffmpeg-python # 0.2.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU1SkN1b2YQL"
      },
      "source": [
        "import numpy as np # 1.19.4\n",
        "import operator as op\n",
        "from itertools import chain\n",
        "from collections import defaultdict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgvxWQRtVizs"
      },
      "source": [
        "# import gym # 0.18.0\n",
        "import gym\n",
        "import pybullet_envs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx5sQQ3RIumz"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp72iXDT4fx-"
      },
      "source": [
        "class AugmentedRS(object):\n",
        "\n",
        "    def __init__(self, env, no_inputs, no_outputs):\n",
        "        super(AugmentedRS, self).__init__()\n",
        "        np.random.seed(1)\n",
        "        self.episode_length = 1000\n",
        "        self.env = env\n",
        "        self.no_inputs = no_inputs\n",
        "        self.no_outputs = no_outputs\n",
        "\n",
        "        self.step_size = 50\n",
        "        self.no_directions = 18\n",
        "        self.sigma_exploration_noise = 0.02\n",
        "        self.no_best_directions = 16\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "        self.n = np.zeros(self.no_inputs)\n",
        "        self.mean = np.zeros(self.no_inputs)\n",
        "        self.var_num = np.zeros(self.no_inputs)\n",
        "        self.variance = np.zeros(self.no_inputs)\n",
        "\n",
        "        self.theta = np.zeros((self.no_outputs, self.no_inputs))\n",
        "\n",
        "    def norm_state(self, state):\n",
        "        prev_mean = self.mean.copy()\n",
        "        self.mean = (state+(self.n*prev_mean))/(self.n+1)\n",
        "        self.var_num += (state-prev_mean)*(state-self.mean)\n",
        "        self.variance = (self.var_num/(self.n+1)).clip(min = 1e-2)\n",
        "        self.n += 1\n",
        "        return (state-self.mean)/np.sqrt(self.variance)\n",
        "\n",
        "    def evaluate(self, inputs, direction=None, delta=None):\n",
        "        if not direction: return self.theta.dot(inputs)\n",
        "        return (direction(self.theta, self.sigma_exploration_noise*delta)).dot(inputs)\n",
        "    \n",
        "    def update(self, rollouts, stddev_reward):\n",
        "        step = np.zeros(self.theta.shape)\n",
        "        for preward, nreward, delta in rollouts:\n",
        "            step += (preward-nreward)*delta\n",
        "        self.theta += (self.learning_rate/(self.no_best_directions*stddev_reward))*step\n",
        "    \n",
        "    def explore(self, direction=None, delta=None):\n",
        "        state = self.env.reset()\n",
        "        frames, done, total_reward = 0., False, 0\n",
        "        while not done and frames < self.episode_length:\n",
        "            state = self.norm_state(state)\n",
        "            action = self.evaluate(state, direction, delta)\n",
        "            state, reward, done, info = self.env.step(action)\n",
        "            if reward > 1: reward = 1\n",
        "            elif reward < -1: reward = -1\n",
        "            total_reward += reward\n",
        "            frames += 1\n",
        "        return total_reward\n",
        "    \n",
        "    def train(self, verbose=True):\n",
        "        for step in range(self.step_size):\n",
        "            score, delta = defaultdict(list), [np.random.rand(*self.theta.shape) for _ in range(self.no_directions)]\n",
        "            for move in range(self.no_directions):\n",
        "                score[move].append(self.explore(op.add, delta[move]))\n",
        "                score[move].append(self.explore(op.sub, delta[move]))\n",
        "            stddev_reward = np.array(list(chain.from_iterable(score.values()))).std()\n",
        "            sorted_keys = sorted(score.keys(), key=lambda x: score[x])[:self.no_best_directions]\n",
        "            rollouts = [[*score[k], delta[k]] for k in sorted_keys]\n",
        "            self.update(rollouts, stddev_reward)\n",
        "            if(verbose): print('step:', step, 'total_reward:', self.explore())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7LEeQ1Vy5L"
      },
      "source": [
        "video_path = '/content/ARS_Videos'\n",
        "\n",
        "env = gym.make('HalfCheetahBulletEnv-v0')\n",
        "env = gym.wrappers.Monitor(env, video_path, force=True)\n",
        "no_inputs, no_outputs = env.observation_space.shape[0], env.action_space.shape[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agllgygYZnz5"
      },
      "source": [
        "ars = AugmentedRS(env, no_inputs, no_outputs)\n",
        "ars.train()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHqlnUv_L95w"
      },
      "source": [
        "print(ars.theta)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAeT0_pbZz5"
      },
      "source": [
        "References\n",
        "\n",
        "1. https://towardsdatascience.com/introduction-to-augmented-random-search-d8d7b55309bd"
      ]
    }
  ]
}